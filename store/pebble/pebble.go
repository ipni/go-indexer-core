package pebble

import (
	"bytes"
	"context"
	"errors"
	"io"
	"sort"

	"github.com/cockroachdb/pebble"
	"github.com/filecoin-project/go-indexer-core"
	"github.com/filecoin-project/go-indexer-core/store/vsinfo"
	logging "github.com/ipfs/go-log/v2"
	"github.com/libp2p/go-libp2p/core/peer"
	"github.com/multiformats/go-multihash"
)

// defaultKeyerLength is the length of hashes generated by the default keyer, blake3Keyer.
const defaultKeyerLength = 20

var (
	log = logging.Logger("store/pebble")

	_ indexer.Interface = (*store)(nil)
	_ indexer.Iterator  = (*iterator)(nil)
)

type (
	store struct {
		db *pebble.DB
		// Only support binary format since in pebble we need the capability to merge keys and
		// there is little reason for store values in any format other than binary for performance
		// characteristics.
		// Note, pebble is using a zero-copy variation of marshaller to allow optimizations in
		// cases where the value need not to be copied. The root level binary codec copies on
		// unmarshal every time.
		vcodec zeroCopyBinaryValueCodec

		newKeyer func() keyer
		closed   bool
	}
	iterator struct {
		closed   bool
		snapshot *pebble.Snapshot
		it       *pebble.Iterator
		keygen   keyer
		vcodec   zeroCopyBinaryValueCodec
	}
)

// New instantiates a new instance of a store backed by Pebble.
// Note that any Merger value specified in the given options will be overridden.
func New(path string, opts *pebble.Options) (indexer.Interface, error) {
	vsInfo, err := vsinfo.Load(path, "pebble")
	if err != nil {
		return nil, err
	}
	// Force binary codec for pebble.
	if vsInfo.Codec != vsinfo.BinaryCodec {
		vsInfo.Codec = vsinfo.BinaryCodec
		if err = vsInfo.Save(path); err != nil {
			return nil, err
		}
	}

	if opts == nil {
		opts = &pebble.Options{}
	}
	// Override Merger since the store relies on a specific implementation of it
	// to handle read-free writing of value-keys; see: valueKeysValueMerger.
	opts.Merger = newValueKeysMerger()
	db, err := pebble.Open(path, opts)
	if err != nil {
		return nil, err
	}

	return &store{
		db:       db,
		newKeyer: func() keyer { return newBlake3Keyer(defaultKeyerLength) },
	}, nil
}

func (s *store) Get(mh multihash.Multihash) ([]indexer.Value, bool, error) {
	keygen := s.newKeyer()
	mhk, err := keygen.multihashKey(mh)
	if err != nil {
		return nil, false, err
	}

	vkb, vkbClose, err := s.db.Get(mhk)
	if err == pebble.ErrNotFound {
		return nil, false, nil
	}
	if err != nil {
		log.Errorw("can't find multihash", "err", err)
		return nil, false, err
	}
	vkbcpy := make([]byte, len(vkb))
	copy(vkbcpy, vkb)
	_ = vkbClose.Close()

	vks, err := s.vcodec.UnmarshalValueKeys(vkbcpy)
	_ = vkbClose.Close()
	if err != nil {
		return nil, false, err
	}

	// Optimistically set the capacity of values slice to the number of value-keys
	// in order to reduce the append footprint in the loop below.
	values := make([]indexer.Value, 0, len(vks))
	for _, vk := range vks {
		vs, vCloser, err := s.db.Get(vk)
		if err == pebble.ErrNotFound {
			// TODO find an efficient way to opportunistically clean up
			continue
		}
		if err != nil {
			log.Errorw("can't find value", "err", err)
			return nil, false, err
		}
		vcpy := make([]byte, len(vs))
		copy(vcpy, vs)
		_ = vCloser.Close()

		v, err := s.vcodec.UnmarshalValue(vcpy)
		if err != nil {
			return nil, false, err
		}
		values = append(values, v)
	}
	return values, len(values) != 0, nil
}

func (s *store) Put(v indexer.Value, mhs ...multihash.Multihash) error {
	if len(v.MetadataBytes) == 0 {
		return errors.New("value missing metadata")
	}

	// Serialize the value first to fail fast if serialization fails and avoid redundant
	// db interaction.
	vs, err := s.vcodec.MarshalValue(v)
	if err != nil {
		return err
	}

	keygen := s.newKeyer()
	vk, err := keygen.valueKey(v, false)
	if err != nil {
		return err
	}

	b := s.db.NewBatch()
	defer b.Close()

	// Sort multihashes before insertion to reduce cursor churn.
	// Note that since multihash key is essentially a prefix plus the multihash itself,
	// sorting the multihashes means their resulting key will also be sorted.
	// The ordered key insertion is the main thing we care about here.
	sort.Slice(mhs, func(i, j int) bool {
		return bytes.Compare(mhs[i], mhs[j]) == -1
	})

	for _, mh := range mhs {
		mhk, err := keygen.multihashKey(mh)
		if err != nil {
			return err
		}
		if err := b.Merge(mhk, vk, pebble.NoSync); err != nil {
			return err
		}
	}

	// Don't bother checking if the value has changed, and write it anyway. Because, otherwise
	// we need to use an IndexedBatch which is generally slower than Batch, and the majority
	// of writing here is the writing of multihashes.
	//
	// TODO: experiment to see if it is indeed faster to always write the value instead of
	//       check if it's changed before writing.
	if err := b.Set(vk, vs, pebble.NoSync); err != nil {
		return err
	}

	return b.Commit(pebble.NoSync)
}

func (s *store) Remove(v indexer.Value, mhs ...multihash.Multihash) error {
	keygen := s.newKeyer()
	dvk, err := keygen.valueKey(v, true)
	if err != nil {
		return err
	}
	b := s.db.NewBatch()
	for _, mh := range mhs {
		mhk, err := keygen.multihashKey(mh)
		if err != nil {
			return err
		}
		if err := b.Merge(mhk, dvk, pebble.NoSync); err != nil {
			return err
		}
	}
	// TODO: opportunistically delete garbage key value keys by checking a list
	//       of removed providers during merge.
	return b.Commit(pebble.NoSync)
}

func (s *store) RemoveProvider(_ context.Context, pid peer.ID) error {
	start, end, err := s.newKeyer().valuesByProviderKeyRange(pid)
	if err != nil {
		return err
	}
	return s.db.DeleteRange(start, end, pebble.NoSync)
}

func (s *store) RemoveProviderContext(pid peer.ID, ctxID []byte) error {
	vk, err := s.newKeyer().valueKey(
		indexer.Value{
			ProviderID: pid,
			ContextID:  ctxID,
		}, false)
	if err != nil {
		return err
	}
	return s.db.Delete(vk, pebble.NoSync)
}

func (s *store) Size() (int64, error) {
	sizeEstimate, err := s.db.EstimateDiskUsage([]byte{0}, []byte{0xff})
	return int64(sizeEstimate), err
}

func (s *store) Flush() error {
	return s.db.Flush()
}

func (s *store) Close() error {
	if s.closed {
		return nil
	}
	ferr := s.db.Flush()
	cerr := s.db.Close()
	s.closed = true
	// Prioritise on returning close errors over flush errors, since it is more likely to contain
	// useful information about the failure root cause.
	if cerr != nil {
		return cerr
	}
	return ferr
}

func (s *store) Iter() (indexer.Iterator, error) {
	keygen := s.newKeyer()
	start, end, err := keygen.multihashesKeyRange()
	if err != nil {
		return nil, err
	}
	snapshot := s.db.NewSnapshot()
	iter := snapshot.NewIter(&pebble.IterOptions{
		LowerBound: start,
		UpperBound: end,
	})
	iter.First()
	return &iterator{
		snapshot: snapshot,
		it:       iter,
		keygen:   keygen,
		vcodec:   s.vcodec,
	}, nil
}

func (i *iterator) Next() (multihash.Multihash, []indexer.Value, error) {
	switch {
	case i.it.Error() != nil:
		return nil, nil, i.it.Error()
	case !i.it.Valid():
		return nil, nil, io.EOF
	}

	mh, err := i.keygen.keyToMultihash(i.it.Key())
	if err != nil {
		return nil, nil, err
	}

	// We don't need to copy the value since it is only used for fetching the
	// indexer.Values, and not returned to the caller.
	bvks := i.it.Value()
	vks, err := i.vcodec.UnmarshalValueKeys(bvks)
	if err != nil {
		return nil, nil, err
	}
	vs := make([]indexer.Value, len(vks))
	for j, vk := range vks {
		bv, c, err := i.snapshot.Get(vk)
		if err != nil {
			return nil, nil, err
		}

		bvcpy := make([]byte, len(bv))
		copy(bvcpy, bv)
		if err := c.Close(); err != nil {
			return nil, nil, err
		}

		v, err := i.vcodec.UnmarshalValue(bvcpy)
		cerr := c.Close()
		if err != nil {
			return nil, nil, err
		}
		if cerr != nil {
			return nil, nil, cerr
		}
		vs[j] = v
	}
	i.it.Next()
	return mh, vs, err
}

func (i *iterator) Close() error {
	// Check if closed already and do not re-call, since pebble
	// panics if snapshot is closed more than once.
	if i.closed {
		return nil
	}
	serr := i.snapshot.Close()
	ierr := i.it.Close()
	i.closed = true
	// Prioritise returning the iterator closure error. Because, that error
	// is more likely to be meaningful to the caller.
	if ierr != nil {
		return ierr
	}
	return serr
}
